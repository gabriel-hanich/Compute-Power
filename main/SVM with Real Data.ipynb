{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from func.datePoint import datePoint\n",
    "from func.util import getProfile, getDateList, getDateInput, readGridDataFromFile\n",
    "from func.valueMaps import ValueMap\n",
    "\n",
    "from datetime import datetime\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "import math\n",
    "import random\n",
    "\n",
    "from mpl_toolkits.mplot3d import axes3d, Axes3D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateRMSE(predicted, observed):\n",
    "    if len(predicted) != len(observed):\n",
    "        print(\"ERROR, two lists aren't the same length\")\n",
    "        \n",
    "    RMSE = 0\n",
    "    for valIndex, val in enumerate(predicted):\n",
    "        RMSE = float(RMSE + (predicted[valIndex] - observed[valIndex])**2)\n",
    "        \n",
    "    RMSE = RMSE/len(predicted)\n",
    "    return RMSE ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainingRow(datePoint):\n",
    "    row = [\n",
    "        datePoint.dayoftheyear,\n",
    "        datePoint.temperature,\n",
    "        datePoint.irradiance,\n",
    "        datePoint.pressure,\n",
    "        datePoint.rainfall,\n",
    "        datePoint.energyData[\"au.nem.nsw1.demand.energy (GWh)\"]\n",
    "    ]\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(xValue, scalerX, scalerY, svr):\n",
    "    transformedVal = scalerX.transform(xValue)\n",
    "    predictedVal = svr.predict(transformedVal)\n",
    "    val = scalerY.inverse_transform(predictedVal)\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "profileName = \"megaDB\"\n",
    "\n",
    "with open(\"./config/download.json\", \"r\", encoding=\"utf-8\") as dataProfileFile:\n",
    "    configData = json.load(dataProfileFile)\n",
    "\n",
    "configData = configData[profileName]\n",
    "dateList = getDateList(datetime.strptime(configData[\"startDate\"], \"%d/%m/%Y\"), datetime.strptime(configData[\"endDate\"], \"%d/%m/%Y\"))\n",
    "\n",
    "for dateIndex, date in enumerate(dateList):\n",
    "    dateList[dateIndex] = datePoint(date)\n",
    "\n",
    "dataTypeCount = len(configData[\"dataTypes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Grid Data\n",
      "Loading Climate Data\n",
      "Loading Wind Data\n",
      "Loaded in 0.296 seconds\n"
     ]
    }
   ],
   "source": [
    "startTime = time.time()\n",
    "# Load data about the energy grid\n",
    "print(\"Loading Grid Data\")\n",
    "if \"grid\" in configData[\"dataTypes\"]:\n",
    "    dataTypeCount = dataTypeCount - 1\n",
    "    with open(f\"./data/processed/grid/{profileName}.csv\", \"r\") as gridDataFile:\n",
    "        gridLines = gridDataFile.readlines()\n",
    "        gridLabels = gridLines[0].split(\",\")[1:]\n",
    "        \n",
    "\n",
    "        for date in dateList:\n",
    "            for rowIndex, row in enumerate(gridLines):\n",
    "                if row.split(\",\")[0] == date.getDateStr():\n",
    "                    dataArr = {}\n",
    "                    for valIndex, val in enumerate(gridLabels):\n",
    "                        dataArr[val] = float(row.split(\",\")[valIndex+1])\n",
    "                    date.energyData = dataArr\n",
    "                    gridLines.remove(row)\n",
    "                    break\n",
    "            # print(f\"Loading Grid Data {str(round((rowIndex+1)/len(gridLines), 2) * 100)[:4]}%\", end=\"\\r\", flush=True)\n",
    "# Load Climate Data\n",
    "print(\"Loading Climate Data\")\n",
    "if dataTypeCount > 0:\n",
    "    with open(f\"./data/processed/climate/{profileName}.csv\", \"r\") as climateFile:\n",
    "        climateData = climateFile.readlines()\n",
    "        climateLabels = climateData[0].split(\",\")\n",
    "        \n",
    "        # Automatically determine the column each datatype is in\n",
    "        dataIndexes = {}\n",
    "        for dataType in configData[\"dataTypes\"]:\n",
    "            for labelIndex, label in enumerate(climateLabels):\n",
    "                if dataType in label:\n",
    "                    dataIndexes[dataType] = labelIndex\n",
    "                    break\n",
    "        \n",
    "        # Validate that start and end dates are the same\n",
    "        if not (climateData[1].split(\",\")[0] == dateList[0].getDateStr() and climateData[-1].split(\",\")[0] == dateList[-1].getDateStr()):\n",
    "            print(f\"FATAL ERROR\\nThe Climate data and studied period do not have the same date range\")\n",
    "            print(f\"Study Period date Range: {dateList[0].getDateStr()} - {dateList[-1].getDateStr()}\")\n",
    "            print(f\"Climate Data date Range: {climateData[1].split(',')[0]} - {climateData[-1].split(',')[0]}\")\n",
    "            exit()\n",
    "\n",
    "        # Load data\n",
    "        climateData = climateData[1:] # Remove labels\n",
    "        for rowIndex, row in enumerate(climateData):\n",
    "            if row.split(\",\")[0] == dateList[rowIndex].getDateStr():\n",
    "                for dataType in configData[\"dataTypes\"]:\n",
    "                    if dataType != \"grid\":\n",
    "                        exec(f\"dateList[{rowIndex}].{dataType} = float(row.split(',')[dataIndexes[dataType]])\")\n",
    "\n",
    "# Load Wind Data\n",
    "print(\"Loading Wind Data\")\n",
    "if configData[\"windFile\"] != \"\":\n",
    "    with open(f\"./data/processed/wind/{configData['windFile']}\", \"r\") as windFile:\n",
    "        windData = windFile.readlines()\n",
    "\n",
    "        # Validate that start and end dates are the same\n",
    "        if not(windData[1].split(\",\")[0] == dateList[0].getDateStr() and windData[-1].split(\",\")[0] == dateList[-1].getDateStr()):\n",
    "            print(f\"FATAL ERROR\\nThe Wind data and studied period do not have the same date range\")\n",
    "            print(f\"Study Period date Range: {dateList[0].getDateStr()} - {dateList[-1].getDateStr()}\")\n",
    "            print(f\"Wind Data date Range: {windData[1].split(',')[0]} - {windData[-1].split(',')[0]}\")\n",
    "            exit()\n",
    "\n",
    "        windData = windData[1:]\n",
    "        for rowIndex, row in enumerate(windData):\n",
    "            row = row.split(\",\")\n",
    "            if row[0] == dateList[rowIndex].getDateStr():\n",
    "                dateList[rowIndex].windspeed = float(row[1])\n",
    "                dateList[rowIndex].windangle = float(row[4])\n",
    "\n",
    "print(f\"Loaded in {round(time.time() - startTime,3)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3013 Produced a rmse of 7.4227958705133139"
     ]
    }
   ],
   "source": [
    "rawData = dateList.copy()\n",
    "random.shuffle(rawData)\n",
    "width = 200\n",
    "trainingValCount = []\n",
    "rmseVals = []\n",
    "\n",
    "iterations = (len(dateList)//width)\n",
    "for i in range(round(iterations)):\n",
    "    # Create Model to predict energy demand\n",
    "    valCount = (i+1)*width\n",
    "    cVal = 100\n",
    "    gammaVal = 1\n",
    "    inputData = np.empty((valCount, 6))\n",
    "    for k in range(valCount):\n",
    "        inputData[k-1] = getTrainingRow(rawData[k-1])\n",
    "\n",
    "    scalerX = StandardScaler()\n",
    "    scalerY = StandardScaler()\n",
    "    X = scalerX.fit_transform(inputData[:, :5])\n",
    "    Y = scalerY.fit_transform(inputData[:,5].reshape(-1, 1))\n",
    "    # create an SVR model with \n",
    "    demandSVR = SVR(kernel='rbf', C=cVal, gamma=gammaVal) \n",
    "\n",
    "    # train the model on the data \n",
    "    demandSVR.fit(X, Y.ravel()) \n",
    "    \n",
    "    x = []\n",
    "    predicted = []\n",
    "    observed = []\n",
    "\n",
    "    for dateIndex, date in enumerate(dateList):\n",
    "        x.append(date.dayoftheyear)\n",
    "        observed.append(date.energyData[\"au.nem.nsw1.demand.energy (GWh)\"])\n",
    "        a = np.empty((1,5))\n",
    "        a[0] = getTrainingRow(date)[:5]\n",
    "        predictedVal = predict(\n",
    "            a.reshape(1, -1), \n",
    "            scalerX, \n",
    "            scalerY, \n",
    "            demandSVR\n",
    "        )\n",
    "        predicted.append(predictedVal)\n",
    "    rmse = calculateRMSE(predicted, observed)\n",
    "    print(f\"\\r{valCount}/{len(dateList)} Produced a rmse of {rmse}\", end=\"\", flush=True)\n",
    "    trainingValCount.append(valCount)\n",
    "    rmseVals.append(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'RMSE')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(trainingValCount, rmseVals)\n",
    "plt.xlabel(\"Number of Training Vals\")\n",
    "plt.ylabel(\"RMSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model to predict energy demand\n",
    "testValCount = 400 # The number of data points that are EXCLUDED and used to assess the model\n",
    "cVal = 100\n",
    "gammaVal = 1\n",
    "inputData = np.empty((len(dateList), 6))\n",
    "for dateIndex, date in enumerate(dateList):\n",
    "    inputData[dateIndex] = getTrainingRow(date)\n",
    "    \n",
    "np.random.shuffle(inputData)\n",
    "trainingData, testData = inputData[:len(dateList)-testValCount,:], inputData[len(dateList)-testValCount:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalerX = StandardScaler()\n",
    "scalerY = StandardScaler()\n",
    "X = scalerX.fit_transform(trainingData[:, :5])\n",
    "Y = scalerY.fit_transform(trainingData[:,5].reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=100, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma=1,\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an SVR model with \n",
    "demandSVR = SVR(kernel='rbf', C=cVal, gamma=gammaVal) \n",
    "\n",
    "# train the model on the data \n",
    "demandSVR.fit(X, Y.ravel()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.383646075187666\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "predicted = []\n",
    "observed = []\n",
    "\n",
    "for rowIndex, row in enumerate(inputData):\n",
    "    x.append(row[0])\n",
    "    observed.append(row[5])\n",
    "    predictedVal = predict(\n",
    "        row[:5].reshape(1, -1), \n",
    "        scalerX, \n",
    "        scalerY, \n",
    "        demandSVR\n",
    "    )\n",
    "    predicted.append(predictedVal)\n",
    "print(calculateRMSE(predicted, observed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x264e104af98>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.scatter(x, observed, label=\"Observed\")\n",
    "plt.scatter(x, predicted, label=\"Predicted\")\n",
    "plt.xlabel(\"Day of the Year\")\n",
    "plt.ylabel(\"Energy Demand\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/SVM/predictions.csv\", \"w\") as predFile:\n",
    "    predFile.write(\"Observed,Predicted\\n\")\n",
    "    for dateIndex, date in enumerate(dateList):\n",
    "        predFile.write(f\"{observed[dateIndex]},{predicted[dateIndex][0]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
