{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from func.datePoint import datePoint\n",
    "from func.util import getProfile, getDateList, getDateInput, readGridDataFromFile\n",
    "from func.valueMaps import ValueMap\n",
    "\n",
    "from datetime import datetime\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateRMSE(predicted, observed):\n",
    "    if len(predicted) != len(observed):\n",
    "        print(\"ERROR, two lists aren't the same length\")\n",
    "        \n",
    "    RMSE = 0\n",
    "    for valIndex, val in enumerate(predicted):\n",
    "        RMSE = float(RMSE + (predicted[valIndex] - observed[valIndex])**2)\n",
    "        \n",
    "    RMSE = RMSE/len(predicted)\n",
    "    return RMSE ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainingRow(datePoint):\n",
    "    row = [\n",
    "        datePoint.dayoftheyear,\n",
    "        datePoint.temperature,\n",
    "        datePoint.irradiance,\n",
    "        datePoint.pressure,\n",
    "        datePoint.rainfall,\n",
    "        datePoint.energyData[\"au.nem.nsw1.demand.energy (GWh)\"]\n",
    "    ]\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(xValue, scalerX, scalerY, svr):\n",
    "    transformedVal = scalerX.transform(xValue)\n",
    "    predictedVal = svr.predict(transformedVal)\n",
    "    val = scalerY.inverse_transform(predictedVal)\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "profileName = \"SRRPeriod\"\n",
    "\n",
    "with open(\"./config/download.json\", \"r\", encoding=\"utf-8\") as dataProfileFile:\n",
    "    configData = json.load(dataProfileFile)\n",
    "\n",
    "configData = configData[profileName]\n",
    "dateList = getDateList(datetime.strptime(configData[\"startDate\"], \"%d/%m/%Y\"), datetime.strptime(configData[\"endDate\"], \"%d/%m/%Y\"))\n",
    "\n",
    "for dateIndex, date in enumerate(dateList):\n",
    "    dateList[dateIndex] = datePoint(date)\n",
    "\n",
    "dataTypeCount = len(configData[\"dataTypes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Grid Data\n",
      "Loading Climate Data\n",
      "Loading Wind Data\n",
      "Loaded in 1.305 seconds\n"
     ]
    }
   ],
   "source": [
    "startTime = time.time()\n",
    "# Load data about the energy grid\n",
    "print(\"Loading Grid Data\")\n",
    "if \"grid\" in configData[\"dataTypes\"]:\n",
    "    dataTypeCount = dataTypeCount - 1\n",
    "    with open(f\"./data/processed/grid/{profileName}.csv\", \"r\") as gridDataFile:\n",
    "        gridLines = gridDataFile.readlines()\n",
    "        gridLabels = gridLines[0].split(\",\")[1:]\n",
    "        \n",
    "\n",
    "        for date in dateList:\n",
    "            for rowIndex, row in enumerate(gridLines):\n",
    "                if row.split(\",\")[0] == date.getDateStr():\n",
    "                    dataArr = {}\n",
    "                    for valIndex, val in enumerate(gridLabels):\n",
    "                        dataArr[val] = float(row.split(\",\")[valIndex+1])\n",
    "                    date.energyData = dataArr\n",
    "                    gridLines.remove(row)\n",
    "                    break\n",
    "            # print(f\"Loading Grid Data {str(round((rowIndex+1)/len(gridLines), 2) * 100)[:4]}%\", end=\"\\r\", flush=True)\n",
    "# Load Climate Data\n",
    "print(\"Loading Climate Data\")\n",
    "if dataTypeCount > 0:\n",
    "    with open(f\"./data/processed/climate/{profileName}.csv\", \"r\") as climateFile:\n",
    "        climateData = climateFile.readlines()\n",
    "        climateLabels = climateData[0].split(\",\")\n",
    "        \n",
    "        # Automatically determine the column each datatype is in\n",
    "        dataIndexes = {}\n",
    "        for dataType in configData[\"dataTypes\"]:\n",
    "            for labelIndex, label in enumerate(climateLabels):\n",
    "                if dataType in label:\n",
    "                    dataIndexes[dataType] = labelIndex\n",
    "                    break\n",
    "        \n",
    "        # Validate that start and end dates are the same\n",
    "        if not (climateData[1].split(\",\")[0] == dateList[0].getDateStr() and climateData[-1].split(\",\")[0] == dateList[-1].getDateStr()):\n",
    "            print(f\"FATAL ERROR\\nThe Climate data and studied period do not have the same date range\")\n",
    "            print(f\"Study Period date Range: {dateList[0].getDateStr()} - {dateList[-1].getDateStr()}\")\n",
    "            print(f\"Climate Data date Range: {climateData[1].split(',')[0]} - {climateData[-1].split(',')[0]}\")\n",
    "            exit()\n",
    "\n",
    "        # Load data\n",
    "        climateData = climateData[1:] # Remove labels\n",
    "        for rowIndex, row in enumerate(climateData):\n",
    "            if row.split(\",\")[0] == dateList[rowIndex].getDateStr():\n",
    "                for dataType in configData[\"dataTypes\"]:\n",
    "                    if dataType != \"grid\":\n",
    "                        exec(f\"dateList[{rowIndex}].{dataType} = float(row.split(',')[dataIndexes[dataType]])\")\n",
    "\n",
    "# Load Wind Data\n",
    "print(\"Loading Wind Data\")\n",
    "if configData[\"windFile\"] != \"\":\n",
    "    with open(f\"./data/processed/wind/{configData['windFile']}\", \"r\") as windFile:\n",
    "        windData = windFile.readlines()\n",
    "\n",
    "        # Validate that start and end dates are the same\n",
    "        if not(windData[1].split(\",\")[0] == dateList[0].getDateStr() and windData[-1].split(\",\")[0] == dateList[-1].getDateStr()):\n",
    "            print(f\"FATAL ERROR\\nThe Wind data and studied period do not have the same date range\")\n",
    "            print(f\"Study Period date Range: {dateList[0].getDateStr()} - {dateList[-1].getDateStr()}\")\n",
    "            print(f\"Wind Data date Range: {windData[1].split(',')[0]} - {windData[-1].split(',')[0]}\")\n",
    "            exit()\n",
    "\n",
    "        windData = windData[1:]\n",
    "        for rowIndex, row in enumerate(windData):\n",
    "            row = row.split(\",\")\n",
    "            if row[0] == dateList[rowIndex].getDateStr():\n",
    "                dateList[rowIndex].windspeed = float(row[1])\n",
    "                dateList[rowIndex].windangle = float(row[4])\n",
    "\n",
    "print(f\"Loaded in {round(time.time() - startTime,3)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model to predict energy demand\n",
    "testValCount = 400 # The number of data points that are EXCLUDED and used to assess the model\n",
    "cVal = 1\n",
    "gammaVal = 0.1\n",
    "inputData = np.empty((len(dateList), 6))\n",
    "for dateIndex, date in enumerate(dateList):\n",
    "    inputData[dateIndex] = getTrainingRow(date)\n",
    "    \n",
    "np.random.shuffle(inputData)\n",
    "trainingData, testData = inputData[:len(dateList)-testValCount,:], inputData[len(dateList)-testValCount:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalerX = StandardScaler()\n",
    "scalerY = StandardScaler()\n",
    "X = scalerX.fit_transform(trainingData[:, :5])\n",
    "Y = scalerY.fit_transform(trainingData[:,5].reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma=0.1,\n",
       "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an SVR model with \n",
    "demandSVR = SVR(kernel='rbf', C=cVal, gamma=gammaVal) \n",
    "\n",
    "# train the model on the data \n",
    "demandSVR.fit(X, Y.ravel()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.855203022291082\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "predicted = []\n",
    "observed = []\n",
    "\n",
    "for rowIndex, row in enumerate(trainingData):\n",
    "    x.append(row[0])\n",
    "    observed.append(row[5])\n",
    "    predictedVal = predict(\n",
    "        row[:5].reshape(1, -1), \n",
    "        scalerX, \n",
    "        scalerY, \n",
    "        demandSVR\n",
    "    )\n",
    "    predicted.append(predictedVal)\n",
    "print(calculateRMSE(predicted, observed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6788775566848949"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX = scalerX.fit_transform(testData[:, :5])\n",
    "testY = scalerY.fit_transform(testData[:,5].reshape(-1, 1))\n",
    "\n",
    "demandSVR.score(testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x200db002bc8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.scatter(x, observed, label=\"Observed\")\n",
    "plt.scatter(x, predicted, label=\"Predicted\")\n",
    "plt.xlabel(\"Day of the Year\")\n",
    "plt.ylabel(\"Energy Demand\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Predicted')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.scatter(observed, predicted)\n",
    "plt.xlabel(\"Observed\")\n",
    "plt.ylabel(\"Predicted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Data\n",
    "labels = [\n",
    "    \"Day of the Year\",\n",
    "    \"Temperature\",\n",
    "    \"Irradiance\",\n",
    "    \"Pressure\",\n",
    "    \"Rainfall\",\n",
    "    \"Observed Demand\",\n",
    "    \"Predicted Demand\",\n",
    "    \"Delta\"\n",
    "]\n",
    "\n",
    "with open(f\"./data/SVM/{profileName}prediction.csv\", \"w\") as predFile:\n",
    "    predFile.write(\",\".join(labels)+\"\\n\")\n",
    "    for row in inputData:\n",
    "        predictedVal = predict(\n",
    "            row[:5].reshape(1, -1), \n",
    "            scalerX, \n",
    "            scalerY, \n",
    "            demandSVR\n",
    "        )\n",
    "        csvRow = ''\n",
    "        for val in row:\n",
    "            csvRow = csvRow + str(val) + \",\"\n",
    "        csvRow = csvRow + str(predictedVal[0]) + \",\"\n",
    "        csvRow = csvRow + str(predictedVal[0]-row[5]) + \",\"\n",
    "        predFile.write(csvRow + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/SVM/SRRPeriodscalerY.joblib']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export Model\n",
    "dump(demandSVR, f\"data/SVM/{profileName}.joblib\")\n",
    "dump(scalerX, f\"data/SVM/{profileName}scalerX.joblib\")\n",
    "dump(scalerY, f\"data/SVM/{profileName}scalerY.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([204.47853625])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr = load(f\"data/SVM/{profileName}.joblib\")\n",
    "\n",
    "xScale = load(f\"data/SVM/{profileName}scalerX.joblib\")\n",
    "yScale = load(f\"data/SVM/{profileName}scalerY.joblib\")\n",
    "\n",
    "b = np.empty((1,5))\n",
    "b[0] = getTrainingRow(dateList[0])[:5]\n",
    "predict(\n",
    "    b,\n",
    "    xScale,\n",
    "    yScale,\n",
    "    svr\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
