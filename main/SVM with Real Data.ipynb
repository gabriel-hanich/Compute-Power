{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from func.datePoint import datePoint\n",
    "from func.util import getProfile, getDateList, getDateInput, readGridDataFromFile\n",
    "from func.valueMaps import ValueMap\n",
    "\n",
    "from datetime import datetime\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "profileName = \"SRRPeriod\"\n",
    "\n",
    "with open(\"./config/download.json\", \"r\", encoding=\"utf-8\") as dataProfileFile:\n",
    "    configData = json.load(dataProfileFile)\n",
    "\n",
    "configData = configData[profileName]\n",
    "dateList = getDateList(datetime.strptime(configData[\"startDate\"], \"%d/%m/%Y\"), datetime.strptime(configData[\"endDate\"], \"%d/%m/%Y\"))\n",
    "\n",
    "for dateIndex, date in enumerate(dateList):\n",
    "    dateList[dateIndex] = datePoint(date)\n",
    "\n",
    "dataTypeCount = len(configData[\"dataTypes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Grid Data\n",
      "Loading Climate Data\n",
      "Loading Wind Data\n",
      "Loaded in 0.291 seconds\n"
     ]
    }
   ],
   "source": [
    "startTime = time.time()\n",
    "# Load data about the energy grid\n",
    "print(\"Loading Grid Data\")\n",
    "if \"grid\" in configData[\"dataTypes\"]:\n",
    "    dataTypeCount = dataTypeCount - 1\n",
    "    with open(f\"./data/processed/grid/{profileName}.csv\", \"r\") as gridDataFile:\n",
    "        gridLines = gridDataFile.readlines()\n",
    "        gridLabels = gridLines[0].split(\",\")[1:]\n",
    "        \n",
    "\n",
    "        for date in dateList:\n",
    "            for rowIndex, row in enumerate(gridLines):\n",
    "                if row.split(\",\")[0] == date.getDateStr():\n",
    "                    dataArr = {}\n",
    "                    for valIndex, val in enumerate(gridLabels):\n",
    "                        dataArr[val] = float(row.split(\",\")[valIndex+1])\n",
    "                    date.energyData = dataArr\n",
    "                    gridLines.remove(row)\n",
    "                    break\n",
    "            # print(f\"Loading Grid Data {str(round((rowIndex+1)/len(gridLines), 2) * 100)[:4]}%\", end=\"\\r\", flush=True)\n",
    "# Load Climate Data\n",
    "print(\"Loading Climate Data\")\n",
    "if dataTypeCount > 0:\n",
    "    with open(f\"./data/processed/climate/{profileName}.csv\", \"r\") as climateFile:\n",
    "        climateData = climateFile.readlines()\n",
    "        climateLabels = climateData[0].split(\",\")\n",
    "        \n",
    "        # Automatically determine the column each datatype is in\n",
    "        dataIndexes = {}\n",
    "        for dataType in configData[\"dataTypes\"]:\n",
    "            for labelIndex, label in enumerate(climateLabels):\n",
    "                if dataType in label:\n",
    "                    dataIndexes[dataType] = labelIndex\n",
    "                    break\n",
    "        \n",
    "        # Validate that start and end dates are the same\n",
    "        if not (climateData[1].split(\",\")[0] == dateList[0].getDateStr() and climateData[-1].split(\",\")[0] == dateList[-1].getDateStr()):\n",
    "            print(f\"FATAL ERROR\\nThe Climate data and studied period do not have the same date range\")\n",
    "            print(f\"Study Period date Range: {dateList[0].getDateStr()} - {dateList[-1].getDateStr()}\")\n",
    "            print(f\"Climate Data date Range: {climateData[1].split(',')[0]} - {climateData[-1].split(',')[0]}\")\n",
    "            exit()\n",
    "\n",
    "        # Load data\n",
    "        climateData = climateData[1:] # Remove labels\n",
    "        for rowIndex, row in enumerate(climateData):\n",
    "            if row.split(\",\")[0] == dateList[rowIndex].getDateStr():\n",
    "                for dataType in configData[\"dataTypes\"]:\n",
    "                    if dataType != \"grid\":\n",
    "                        exec(f\"dateList[{rowIndex}].{dataType} = float(row.split(',')[dataIndexes[dataType]])\")\n",
    "\n",
    "# Load Wind Data\n",
    "print(\"Loading Wind Data\")\n",
    "if configData[\"windFile\"] != \"\":\n",
    "    with open(f\"./data/processed/wind/{configData['windFile']}\", \"r\") as windFile:\n",
    "        windData = windFile.readlines()\n",
    "\n",
    "        # Validate that start and end dates are the same\n",
    "        if not(windData[1].split(\",\")[0] == dateList[0].getDateStr() and windData[-1].split(\",\")[0] == dateList[-1].getDateStr()):\n",
    "            print(f\"FATAL ERROR\\nThe Wind data and studied period do not have the same date range\")\n",
    "            print(f\"Study Period date Range: {dateList[0].getDateStr()} - {dateList[-1].getDateStr()}\")\n",
    "            print(f\"Wind Data date Range: {windData[1].split(',')[0]} - {windData[-1].split(',')[0]}\")\n",
    "            exit()\n",
    "\n",
    "        windData = windData[1:]\n",
    "        for rowIndex, row in enumerate(windData):\n",
    "            row = row.split(\",\")\n",
    "            if row[0] == dateList[rowIndex].getDateStr():\n",
    "                dateList[rowIndex].windspeed = float(row[1])\n",
    "                dateList[rowIndex].windangle = float(row[4])\n",
    "\n",
    "print(f\"Loaded in {round(time.time() - startTime,3)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model to predict energy demand\n",
    "testValCount = 200 # The number of data points that are EXCLUDED and used to assess the model\n",
    "inputData = np.empty((len(dateList), 6))\n",
    "for dateIndex, date in enumerate(dateList):\n",
    "    inputData[dateIndex][0] = date.dayoftheyear\n",
    "    inputData[dateIndex][1] = date.temperature\n",
    "    inputData[dateIndex][2] = date.irradiance\n",
    "    inputData[dateIndex][3] = date.pressure\n",
    "    inputData[dateIndex][4] = date.rainfall\n",
    "    inputData[dateIndex][5] = date.energyData[\"au.nem.nsw1.demand.energy (GWh)\"]\n",
    "\n",
    "np.random.shuffle(inputData)\n",
    "trainingData, testData = inputData[:len(dateList)-testValCount,:], inputData[len(dateList)-testValCount:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(xValue, scalerX, scalerY, svr):\n",
    "    transformedVal = scalerX.transform(xValue)\n",
    "    predictedVal = svr.predict(transformedVal)\n",
    "    val = scalerY.inverse_transform(predictedVal)\n",
    "    return val\n",
    "#     return scalerY.inverse_transform(svr.predict(scalerX.transform(xValue)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalerX = StandardScaler()\n",
    "scalerY = StandardScaler()\n",
    "X = scalerX.fit_transform(trainingData[:, :5])\n",
    "Y = scalerY.fit_transform(trainingData[:,5].reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an SVR model with a linear kernel \n",
    "demandSVR = SVR(kernel='rbf') \n",
    "  \n",
    "# train the model on the data \n",
    "demandSVR.fit(X, Y.ravel()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = predict(\n",
    "    testData[:, :5],\n",
    "    scalerX,\n",
    "    scalerY,\n",
    "    demandSVR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(testData[:,1], val, label=\"Predicted\")\n",
    "plt.scatter(testData[:,1], testData[:,5], label=\"Observed\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
